# Sarcasm Detector
2025 Spring\
Diablo Valley College\
Project Bracket

---

### __Authors__

Heidi\
[@heidi415D](https://github.com/heidi415D)

Brymiri\
[@hBrymiri](https://github.com/hBrymiri)

Johnson Liu\
[@johnson-liu-code](https://github.com/johnson-liu-code)

---

### __Resources__

#### __Data__

Kaggle dataset with Reddit posts classified as either sarcastic or not sarcastic.
1. https://www.kaggle.com/datasets/danofer/sarcasm/data?select=train-balanced-sarcasm.csv

#### __Theoretical Foundations__
<ins>Natural language processing</ins> –
1. https://en.wikipedia.org/wiki/Natural_language_processing
2. https://mlarchive.com/natural-language-processing/text-classification-sentiment-analysis/

<ins>word2vec model</ins> –
1. https://en.wikipedia.org/wiki/Word2vec
2. https://mlarchive.com/natural-language-processing/word2vec-nlp-with-contextual-understanding/

<ins>GloVe model</ins> –
1. https://en.wikipedia.org/wiki/GloVe

#### __Sample Work__
Project applying word2vec and GloVe to classifying news headlines. Trained using headlines from _The Onion_ and the _The Huffington Post_.
1. https://www.kaggle.com/code/madz2000/sarcasm-detection-with-glove-word2vec-83-accuracy

---

### __Important Dates ( taken from club-provided syllabus )__

##### <ins>Week 5/6 — April 16 & April 23, 2025</ins>
Development continues on in week 5 in preparation for the **mid-semester showcase in week 6**. Groups are now in the middle of the semester meaning that they will present what progress they have so far. The mid-semester showcase does not mean that groups have to be halfway done with their projects.

##### <ins>Week 7 — April 30, 2025</ins>
At this point **groups should be more than halfway done with their project** or close to finished in preparation for the final week as well as finals. Project managers should check with members on the final schedule to ensure projects are done and not rushed in the final week.

##### <ins>Week 8 — May 7, 2025</ins>
**Groups should be close to wrapping up their projects** or should be completely done with the projects. This week will be focused mainly on the final project showcase in which judges will determine who has the best project. Groups may want to **prepare ahead of time with presentations**, graphics, and props to enhance their presentations.

---
### __Data Visualization__

#### Word cloud - Sarcastic
![placeholder-text](data_visualization/wordcloud_sarcastic.png)

#### Word cloud - Not Sarcastic
![placeholder-text](data_visualization/wordcloud_not_sarcastic.png)

#### Word frequency in comments
![placeholder-text](data_visualization/words_in_comments.png)

---

### __Records__

#### <ins>20250404</ins>

##### Notes
— Johnson
1. Heidi and Brymiri, I will be using this file to keep track of out progress and to assign tasks amongst the team members.
2. I will also use this file to keep track of important dates specified by the club.
3. Please use this file to record any important thoughts that you come up with during the course of the project.
4. You can also use this file to add important notes that you want the team to remember.

##### To-do
###### For Johnson:
- [x] Create Github repository.
- [x] Look up relavant resources.
- [x] Look up relavant data.
- [ ] Plan out our timeline and general to-do's / tasks for each team member.


#### <ins>20250408</ins>

##### To-do
###### For Heidi:
- [ ] Review the theoretical resources and begin drafting a short write-up for our team to reference.
- [ ] Optional - Also look up introductory machine learning resources to clarify specific topics in the write-up, especially if you think they’d be helpful for the team.

###### For Bryan:
- [ ] Write code to extract a specific Reddit post, along with its parent post and the name of the subreddit where it was posted.


#### <ins>20250412</ins>

##### Notes
— Johnson
1. Organized files into folders based on their purpose for better structure and clarity.
2. Expanded and refined the files used for data extraction.
3. Developed files dedicated to data visualization.
4. Generated figures to help us better understand the data.
